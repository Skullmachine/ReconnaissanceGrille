\documentclass[twoside]{EPURapport}

\usepackage{graphicx,mwe,lipsum}
\usepackage[T1]{fontenc}
\usepackage[final]{pdfpages}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}


\thedocument{Reconnaissance de grille}{Projet de développement embarqué}{Projet de développement embarqué}

\grade{Sp\'ecialit\'e Informatique Industrielle \\ 4\ieme ann\'ee\\ 2014-2015}

\authors{Alexandre BILLAY, Thibault ARTUS}{alexandre.billay@etu.univ-tours.fr, theskullmachine@gmail.com}
	{}{}
	{}{}

\supervisors{Yannick KERGOSIEN}{yannick.kergosien@univ-tours.fr}
	{}{}
	{}{}
	{Polytech'Tours}

\abstracts{}
{}
{}
{}



\begin{document}

\introduction
 
Dans le cadre de notre quatrième année au sein de Polytech'Tours, nous avons dû réaliser un projet de développement embarqué sur une durée égale à 4 mois. Après 2 heures de présentation des sujets, nous avons choisi le développement et intégration d'un système de reconnaissance de grille sur tablette Androïd. Ce projet découle d'un PFE (Projet de Fin d'\'Etude), le Stacker Crane Probleme interprété par un pont roulant, réalisé lors l'année précédente par Thibault Morelle. Quant à notre projet, il fut décidé de reprendre la partie du PFE sur la reconnaisance automatique des objets à déplacer par simple prise de photo. Cette partie ne fonctionnait pas. 
Notre projet a dû être fait en collaboration avec Clément Laloubeyre, un élève en cinquième année qui a pris la suite du PFE de Thibault Morelle.

\chapter{Conduite du projet}

	\section{Cahier des charges}

L'objectif du projet est de concevoir un module de détection d'une grille et de localisation de deux types de pièces de couleurs dans cette grille à l'aide de la caméra d'une tablette Android. Ce module sera à intégrer dans une application mobile permettant de contrôler un pont roulant ayant pour but de déplacer les objets détectés dans cette grille.

\section{\'Etat des lieux}

Lors de notre reprise du projet, l'application permettait la détection des formes et des couleurs d'une image créée sous \textit{Paint} alors qu'une image prise à l'aide de la caméra de la tablette ne permettait pas ce fonctionnement. 

	\section{Chronogramme réel du projet}

		\begin{figure}[h!]
				\centering
					\includegraphics[scale=0.4]{images/gantt.png}
					\caption{Diagramme de Gantt}
		\end{figure}

Après notre premier entretien avec Clément, nous avons réalisé tout au long du projet le diagramme de Gantt réel.

Au début du projet, nous avons fait nos tâches en parallèle. 
La décomposition des fonctions du programme existant a été réalisé par Thibault ainsi que leurs définition des points d'entrée et sortie (en rouge).
La recherche sur les techniques de détections d'image et la rédaction de synthèse sur ces techniques a été produite par Alexandre (en vert).
Le reste du projet, a été fait ensemble, c'est à dire la prise en main du Java ainsi que les logiciels attachés, l'analyse d'une technique implémentable envisageable, le débogage et la livraison de l'application.

\newpage

	\section{Software utilisés}

Lors de ce projet nous avons pu mettre en pratique différents software ci-dessous. Il faut savoir que l'installation des 3 premiers fut un challenge car nous n'avions pas les versions de logiciels utilisés par notre prédécesseur. Merci à Clément Laloubeyre qui nous a aidé à la mise en marche de ceux-ci sur nos 2 ordinateurs personnels.
\vspace{0.2cm}

\begin{itemize}
	\item \textbf{ADT Bundle }(IDE Eclipse 4.2 + SDK Manager): compatible Java 7. La version de l'application Androïd est la 4.3.
	
	\begin{figure}[h!]
				\centering
					\includegraphics[scale=0.4]{images/adt.png}
					\caption{Android Developer Tools}
		\end{figure}
	
	\item \textbf{Plugin Lejos} pour Eclipse: nécessitant l'installation de drivers pour les briques NXT.
	
	\begin{figure}[h!]
				\centering
					\includegraphics[scale=0.4]{images/lejos.jpg}
					\caption{Plugin Lejos pour Eclipse}
		\end{figure}
	
	\item \textbf{Genymotion:} émulateur plus performant que celui inclus à l'ADT. Nous avons pu simuler la quasi totalité de nos actions sur une Galaxy Tab 3 émulée.
	
	\begin{figure}[h!]
				\centering
					\includegraphics[scale=0.2]{images/genymotion.jpg}
					\caption{\'Emulateur Androïd Genymotion}
	\end{figure}
	
	\item \textbf{GitHub:} logiciel de gestion de version décentralisé. Sachant que nous passerions des périodes en entreprise, au large, durant notre projet, nous avons opté pour utiliser GitHub permettant de nous coordinner sur le travail effectué.
	
		\begin{figure}[h!]
				\centering
					\includegraphics[scale=0.2]{images/github.png}
					\caption{Logo Github}
	\end{figure}
	
\end{itemize} 

\chapter{Analyse des classes}

Dans ce chapitre, nous présentons les classes Hough.java, PictureHandler.java et HoughView sur lesquelles nous avons dû travailler.

	\section{Hough.java}

		\subsection{Constructeur}

			\textbf{public Hough(int width, int height)}
			\vspace{0.2cm}
			
			\textbf{Points d'entrée :} 
			\vspace{0.2cm}
			
			\begin{itemize}
				\item width: largeur de l'image; entier
				\item height: hauteur de l'image; entier
			\end{itemize}

		\subsection{Méthodes (Transformée de Hough)}

			\textbf{public void vote(int x, int y) }
			\vspace{0.2cm}
			
			\textbf{Points d'entrée :} 
			\vspace{0.2cm}
			
			\begin{itemize}
				\item x: largeur de l'image/2; entier
				\item y: hauteur de l'image/2; entier
			\end{itemize}
			\vspace{1cm}
			
			
			\textbf{public List<double[]> getWinners(int threshold, int radius)}; on récupère la valeur extreme de la transformée de Hough
			\vspace{0.2cm}
			
			\textbf{Points d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item threshold : seuil de l'image
				\item radius : rayon
			\end{itemize}
			\vspace{0.2cm}

			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item winners: tableau contenant les valeurs extremes de Rho et Théta; tableau de réels
			\end{itemize}
			\vspace{1cm}

			\textbf{private int distance(int r0, int t0, int r1, int t1)}
			\vspace{0.2cm}
			
			\textbf{Points d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item r0: point 0 de Rho; entier
				\item t0: point 0 de Théta; entier
				\item r1: point 1 de Rho; entier
				\item t1: point 1 de Théta; entier
			\end{itemize}
			\vspace{0.2cm}
			
			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item dist: Retourne la valeur minimale entre dist et le maximum de la valeur absolue entre  (r0-r1) et (t0-t1); entier
			\end{itemize}
			
		\subsection{Méthodes (Conversions)}

			\textbf{public int RhoToIndex(double rho)}
			\vspace{0.2cm}
			
			\textbf{Points d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item rho: réel
			\end{itemize}

			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item On retourne un entier qui est spécialement converti pour rentrer dans notre index (matrice de valeur de Rho)
			\end{itemize}
			\vspace{1cm}
			
			\textbf{public double IndexToRho(int index)}
			\vspace{0.2cm}
			
			\textbf{Points d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item index: entier
			\end{itemize}
			\vspace{0.2cm}
			
			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item On retourne un reel qui vient de la conversion d'un entier (Rho) de la matrice d'index.
			\end{itemize}
			\vspace{1cm}
			
			\textbf{public int ThetaToIndex(double theta)}
			\vspace{0.2cm}
			
			\textbf{Point d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item theta: réel
			\end{itemize}
			\vspace{0.2cm}
			
			\textbf{Point de sortie :}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item On retourne un entier qui est spécialement converti pour rentrer dans notre index (matrice de valeur de Theta)
			\end{itemize}
			\vspace{1cm}
			
			\textbf{public double IndexToTheta(int index)}
			\vspace{0.2cm}
			
			\textbf{Point d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item index: entier
				\vspace{0.2cm}
			\end{itemize}

			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item On retourne un réel qui vient de la conversion d'un entier (Theta) de la matrice d'index.
			\end{itemize}
			\vspace{1cm}
			
			\textbf{public double[] rhotheta\_to\_ab(double rho,double theta)} : conversion de rho et theta pour permettre son utilisation dans une équation de droite Y=a*X+b
			\vspace{0.2cm}
			
			\textbf{Point d'entrée:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item rho: reel 
				\item theta: reel
			\end{itemize}
			\vspace{0.2cm}
			
			\textbf{Point de sortie:}
			\vspace{0.2cm}
			
			\begin{itemize}
				\item a, b: reel
			\end{itemize}
			\vspace{1cm}
			
		\subsection{Accesseurs}

			\textbf{public int getMaxIndexTheta()}
			\vspace{0.2cm}
			
			\textbf{Point de sortie : }
			\vspace{0.2cm}

			\begin{itemize}
				\item maxIndexTheta: entier; on récupère la valeur maximale de theta dans l'index
				\vspace{1cm}
			\end{itemize}

			\textbf{public int getMaxIndexRho()}
			\vspace{0.2cm}

			\textbf{Point de sortie:}
			\vspace{0.2cm}

			\begin{itemize}
				\item maxIndexRho: entier; on récupère la valeur maximale de rho dans l'index
				\vspace{1cm}
			\end{itemize}


			\textbf{public int[][] getAccumulator()}
			\vspace{0.2cm}

			\textbf{Point de sortie:}
			\vspace{0.2cm}

			\begin{itemize}
				\item acc: tableau 2 dimensions d'entier; on récupère les \textit{winner}
				\vspace{1cm}
			\end{itemize}


	\section{PictureHandler.java}

		\subsection{Constructeur}
		
		\textbf{public PictureHandler(PhotoFragment cxt, int callerId)}
		\vspace{0.2cm}
		
		\textbf{Points d'entrée:}
		\vspace{0.2cm}
		
		\begin{itemize}
			\item cxt: photo du parent; PhotoFragment
			\item callerId: entier
		\end{itemize}
	
		
		\subsection{Méthodes}

		\textbf{public void onPictureTaken(byte[] data, Camera camera)}; decode de l'image Bitmap
		\vspace{0.2cm}

		\textbf{Points d'entrée:}
		\vspace{0.2cm}

		\begin{itemize}
			\item data: tableau d'octets
			\item camera: Camera
		\end{itemize}
		\vspace{1cm}

		\textbf{protected void onPreExecute()}: pour chaque nouvelle ligne, on créé un nouvel HashMap les contenant
		\vspace{1cm}

		\textbf{protected Void doInBackground(Bitmap... pictureFile)}: dans cette méthode, on charge l'image enregistré puis on éxécute la transformée de Hough puis l'extraction des lignes de l'image.
		\vspace{0.2cm}

		\textbf{Points d'entrée:}
		\vspace{0.2cm}

		\begin{itemize}
			\item pictureFile: type Bitmap
		\end{itemize}
		\vspace{1cm}

		\textbf{protected void onPostExecute(Void result)}
		\vspace{1cm}

		\textbf{private void doTH(Bitmap img0)}: application de l'algorithme de Hough sur l'image
		\vspace{0.2cm}

		\textbf{Points d'entrée:}
		\vspace{0.2cm}

		\begin{itemize}
			\item img0: type Bitmap
		\end{itemize}
		\vspace{1cm}

		\textbf{private void doLinesExtraction(Bitmap img0)}: permet de faire l'extraction des lignes suite à la transformée de Hough
		\vspace{0.2cm}

		\textbf{Points d'entrée:}
		\vspace{0.2cm}

		\begin{itemize}
			\item img0: type Bitmap
		\end{itemize}
		\vspace{1cm}

		\textbf{private void sendLinesToDrawToUiThread(HashMap<Integer, ArrayList<Point>> lines)}: Permet de dessiner les lignes stockées dans le Hashmap.
		\vspace{0.2cm}

		\textbf{Points d'entrée:} 
		\vspace{0.2cm}

		\begin{itemize}
			\item lines: type HashMap<Integer, ArrayList<Point>>; Un tableau qui a comme clef des entiers permettant de retrouver plus facilement les listes de points de chaque ligne précédement stockée. 
		\end{itemize}

\chapter{Causes des dysfonctionnements possibles}

Au fur et à mesure des analyses faites sur l'application, en croisant les résultats des images réelles avec celles créées sous Paint, nous en sommes arrivés à 4 causes possibles de dysfonctionnement:
\vspace{0.2cm}

\begin{enumerate}
	\item Les photos prises par la tablette ont des couleurs mal prises en charge par l'algorithme de détection de couleur, les filtres fonctionneraient mal pour isoler les lignes noires.
	\vspace{0.2cm}
	
	\item La transformée de Hough serait faussée et/ou pas assez précise. Nous avons fait des recherches sur des alternatives possibles décrites dans le chapitre suivant.
	\vspace{0.2cm}
	
	\item La mauvaise gestion du format. Les images scrutées par l'algorithme sont de format différent (Bitmap, jpeg et png).
	\vspace{0.2cm}
	
	\item Les photos prises avec la caméra sont trop inclinées. 
	\vspace{0.2cm}
\end{enumerate}

\chapter{Recherches}

	\section{Détection de formes}

		\subsection{Tranformée de Hough}

		Le principe qui sous-tend la transformée de Hough est qu'il existe un nombre infini de lignes qui passent par un point, dont la seule différence est l'orientation (l'angle). Le but de la transformée est de déterminer lesquelles de ces lignes passent au plus près du schéma attendu.
		\vspace{0.2cm}
		
Dans la transformée de Hough, dite aussi transformée standard de Hough ou SHT, chaque ligne est un vecteur de coordonnées paramétriques :
\vspace{0.2cm}

\begin{itemize}
	\item $\theta$ : l'angle
	\item $\rho$ : la norme du vecteur (la longueur du segment perpendiculaire à la droite d'angle $\theta$ et passant par l'origine)
\end{itemize}
\vspace{0.2cm}

En transformant toutes les lignes possibles qui passent par un point, c'est-à-dire en calculant la valeur de $\rho$ pour chaque $\theta$, on obtient une sinusoïde unique appelée espace de Hough. Si les courbes associées à deux points se coupent, l'endroit où elles se coupent dans l'espace de Hough correspond aux paramètres d'une droite qui relie ces deux points.
\vspace{4cm}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.55]{images/hough.png}
	\caption{Transformée de Hough}
\end{figure}

\newpage

		\subsection{Codage de Freeman absolu}

Codage avec un nombre limité de bits de la direction locale d'un élément de contour défini dans une image discrète, puis constitution d'une chaine de codes à partir d'un pixel initial, considérant qu'un élément de contour relie 2 pixels connexes.

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.5]{images/freeman_absolu.png}
	\caption{Constitution d'une chaîne de codes}
\end{figure}

		\subsection{Codage de Freeman relatif}

Dans cette variante on code le changement de direction plutôt que de la direction.

\begin{figure}[h!]
	\centering
		\includegraphics[scale=1]{images/freeman_relatif1.png}
		\caption{Codage du changement de direction}
\end{figure}

Le code de Freeman standard est invariant en translation uniquement. Le code Freeman relatif est invariant en translation et aux rotations de 45°.
\vspace{0.2cm}

Codage sur 2 bits pour connexité 4. Codage sur 3 bits pour connexité 8. Codage sur 4 bits pour connexité 8 + longueur 2. Etc...

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.4]{images/freeman_relatif2.png}
		\caption{Nombre de directions}
\end{figure}


\subsection{Régression linéaire}

On approche un ensemble de points par un segment de droite. Pour cela on minimise un résidu entre le modèle (la droite) et les données (points repérés par leurs coordonnées).
\vspace{0.2cm}


\chapter{Travaux effectués}

\section{Apprentissage des bases du Java}

Lors de la réunion d'attribution des projets de développement embarqué, nous avons été choisi au hasard pour le réalisé. De ce fait, nous avons été pris au dépourvu sur le Java surtout que les cours permettant son apprentissage n'arrive qu'une semaine avant la dernière semaine du projet. Nous avons donc pu pallier ce problème en suivant des tutoriels en ligne tels que ceux d'\textit{Open Classroom} ou ceux de \textit{Developpez.com}. 

\section{Analyse de l'application existante}

L'application Androïd du pont roulant n'était malheureusement pas très bien documentée. En plus de la difficulté de l'apprentissage d'un nouveau langage, nous n'avons pas pu nous rattaché à un diagramme UML ou même à un descriptif des méthodes utilisés. Nous avons dû se rattacher aux seuls commentaires parsemés. Le langage objet a été un rempart de plus, nous avons dû inspecter par quoi était appelé les différents objets. Nous avons donc pour des soucis d'évolutivité, définit les points d'entrées et sorties des classes sur lesquelles nous avons travaillé.

\section{Réécriture des filtres en niveau de gris}

On s'est attaché à vérifier si le bug de l'application existante, lors de la sélection d'une photo prise à l'aide de la caméra de la tablette, venait de certains seuils de couleur qui seraient dépassés. C'est pourquoi, on a créé une procédure de conversion en niveau de gris permettant d'obtenir le quadrillge. Cet essai n'a pas été probant puisque le bug persistait.

\lstinputlisting[language=Java, breaklines=true, commentstyle=\color{mygreen}, numbers=left, frame=single]{code/niveau_gris.java}	

\section{Tests en mode debug avec Genymotion}

Nous voulions un outil permettant l'émulation d'Androïd pour passer en mode debug l'application. Nous avons utilisé l'émulateur de base présent dans ADT avant de se convertir à Genymotion, un outil bien plus ergonomique.

L'un des problèmes rencontrés, était le temps d'exécution du programme. Sachant qu'il y a du traitement d'image, l'algorithme mouline relativement beaucoup. De plus, on sait que le mode debug ralentit les traitements. La recherche d'erreur fut plutôt longue. On a réussi cependant, a capturer des résultats probant. On a pu comparer entre la photo de \textit{Paint} et la photo prise avec la tablette, le nombre de ligne que l'algorithme faisait remonter à l'aide de la méthode \textbf{getWinner}. 
\vspace{0.2cm}

\begin{itemize}
	\item La photo \textit{Paint}:
	\vspace{0.2cm}
	
	\lstinputlisting[breaklines=true, commentstyle=\color{mygreen}, numbers=left, frame=single]{code/paint.txt}
	\vspace{0.2cm}
	
	Il y a 18 lignes de détectés avec des $\theta$ et $\rho$ envisageable suivant notre cas.
	
	\newpage
	
	\item La photo de la tablette:
	\vspace{0.2cm}
	
	\lstinputlisting[breaklines=true, commentstyle=\color{mygreen}, numbers=left, frame=single]{code/reelle.txt}
	\vspace{0.2cm}
	
	Il n'y a que 15 lignes de détectés avant que cela ne lève une exception, alors que la grille en comporte 18. De plus, il y a des valeurs de rho qui ne collent avec nos estimations. Exemples: 173.5 et 24.5 degrés.
	
	Nous avons donc décidé de nous affranchir de ce code existant pour valider fonctionnellement notre module en standalone. Arès cette étape vérifiée, on pourrait l'implémenter dans l'application existante.
\end{itemize}

\section{Réécriture d'une transformée de Hough en standalone}

La réécriture de la transformée de Hough en dehors de l'application était primordiale car nous devions valider son fonctionnement. Un programme a été créé par Xavier Philippeau et dont on s'est inspiré pour répondre à notre besoin. Après quelques réglages, une interface et l'algorithme de la transformée de l'application standalone furent mises au point.

\chapter{Démonstration}

Une vidéo faites par nos soin a été uploadé sur \textit{YouTube} à cette adresse: \url{http://youtu.be/tXzoQx-SrhM}

La vidéo présente malheureusement une version obsolète de l'application. La dernière version n'affiche qu'une ligne verte au lieu d'une double ligne.
\vspace{1cm}

Exemples d'application de la transformée de Hough de notre application sur différentes prises de vue de la grille où se situe le pont roulant:
\vspace{1cm}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.4]{images/real_photo1.jpg}
		\caption{Photo 1}
\end{figure}

\newpage

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.4]{images/real_photo2.jpg}
		\caption{Photo 2}
\end{figure}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.4]{images/real_photo3.jpg}
		\caption{Photo 3}
\end{figure}

L'application est simple d'utilisation, il suffit d'ouvrir une image d'un format quelconque et ensuite de lancer la détection des lignes de celle-ci. Sur les 3 photos montrées ci-dessus, on peut s'apercevoir qu'il y a la détection d'une ligne à la verticale gauche en trop. Le rebord est détecté comme ligne noire.

\conclusion
Lors de ce projet, nous avons pu mettre en oeuvre des compétences en conduite de projet et en Java. Le besoin initial a été rempli, c'est à dire, avoir une solution intégrable de la transformée de Hough fonctionnelle à l'application Androïd existante. Clément Laloubeyre, l'étudiant faisant son PFE sur ce sujet, se chargera de l'intégré suivant nos points d'entrée et nos points de sortie. Nous n'avons malheureusement pas eu le temps de rédiger la documentation nécessaire pour une compréhension au premier coup d'oeuil mais l'on peut se féléiciter d'avoir un code commenté correctement. Sachant que notre apprentissage des diagrammes UML n'intervient qu'après le combat pour ce projet, nous n'avons pas pu prendre le temps nécessaire à sa compréhension et à sa réalisation.
En conclusion, ce projet fut très intéressant même si au départ nous n'étions pas déterminé à le choisir. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\annexe

		
\end{document}

